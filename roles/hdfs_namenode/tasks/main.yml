---
- name: Stop namenode process
  systemd:
    state: stopped
    daemon_reload: yes
    name: hdfs_namenode

#On the primary, format the filesystem
- name: Format namenode
  become: yes
  become_user: hdfs
  shell:
    cmd:
      echo -e "Y\nN" | /usr/local/bin/hadoop-invoker.sh hdfs hadoop-env.sh namenode -format > "{{ hadoop_dfs_name }}/formatted"
    executable: /bin/bash
    creates: "{{ hadoop_dfs_name }}/formatted"
  when: primary|bool

# Initialize the shared edits
- name: Initialize shared edit
  become: yes
  become_user: hdfs
  shell:
    cmd:
      /usr/local/bin/hadoop-invoker.sh hdfs hadoop-env.sh namenode -initializeSharedEdits > "{{ hadoop_dfs_name }}/shared_edits_initialized"
    executable: /bin/bash
    creates: "{{ hadoop_dfs_name }}/shared_edits_initialized"
  when: primary|bool

# And format the zkfc
- name: Format zkfc
  become: yes
  become_user: hdfs
  shell:
    cmd:
      echo -e "Y\nN" | /usr/local/bin/hadoop-invoker.sh hdfs hadoop-env.sh zkfc -formatZK > "{{ hadoop_dfs_name }}/zkFormatted"
    executable: /bin/bash
    creates: "{{ hadoop_dfs_name }}/zkFormatted"
  when: primary|bool


# Then start the primary, so the secondary will have something to sync with
- name: Start namenode process
  systemd:
    state: restarted
    daemon_reload: yes
    name: hdfs_namenode
    enabled: true
  when: primary|bool

# Sync the secondary namenode
- name: Bootstrap HA
  become: yes
  become_user: hdfs
  shell:
    cmd:
      /usr/local/bin/hadoop-invoker.sh hdfs hadoop-env.sh namenode -bootstrapStandby > "{{ hadoop_dfs_name }}/bootstrapped"
    executable: /bin/bash
    creates: "{{ hadoop_dfs_name }}/bootstrapped"
  when: not (primary | bool)


# Start both
- name: Start namenode process
  systemd:
    state: restarted
    daemon_reload: yes
    name: hdfs_namenode
    enabled: true

# Start the failover controllers
- name: Start namenode zkfc process
  systemd:
    state: restarted
    daemon_reload: yes
    name: hdfs_zkfc
    enabled: true


- name: create basic directory structure
  become: yes
  become_user: hdfs
  command: |
    hdfs dfs -mkdir /tmp  \
    	/history /history/app-logs  /history/spark-history    \
    	/history/mr-history /history/mr-history/done /history/mr-history/tmp
    	/history/timeline-server /history/timeline-server/active /history/timeline-server/done /history/timeline-server/generic-history \
    	/user /user/abrsadm

    hdfs dfs -chmod o+rx /user /history
    hdfs dfs -chmod a+rwx /tmp

    hdfs dfs -chown -R hdfs:hadoop /history /user

    hdfs dfs -chown -R yarn:hadoop /history/app-logs /history/timeline-server

    hdfs dfs -chown -R mapred:hadoop /history/mr-history

    hdfs dfs -chown -R spark:hadoop /history/spark-history

    hdfs dfs -chown -R abrsadm:abrsadm /user/abrsadm
  when: primary|bool
