---

- name: Create Name dir
  file:
    path: "{{hadoop_dfs_name}}"
    state: directory
    owner: "{{hdfs_user}}"
    group: "{{hdfs_user}}"


- include: initialize_hdfs.yml
  when: wipe_hdfs | bool


# Start both
- name: Start namenode process
  systemd:
    state: restarted
    daemon_reload: yes
    name: hdfs_namenode
    enabled: true

# Start the failover controllers
- name: Start namenode zkfc process
  systemd:
    state: restarted
    daemon_reload: yes
    name: hdfs_zkfc
    enabled: true


- name: create basic directory structure
  become: yes
  become_user: hdfs
  shell: |
    source /etc/profile.d/hadoop.sh
    source /etc/profile.d/kerberos.sh

    kinit -kt {{keytab_dir}}/{{hdfs_user}}.headless.keytab {{hdfs_user}}

    hdfs dfs -mkdir /tmp  \
        /system \
    	/history /history/app-logs  /history/spark-history    \
    	/history/mr-history /history/mr-history/done /history/mr-history/tmp \
    	/history/timeline-server /history/timeline-server/active /history/timeline-server/done /history/timeline-server/generic-history \
    	/user /user/abrsadm;

    hdfs dfs -chmod a+rwx /tmp;

    hdfs dfs -chmod o+rx /user;

    hdfs dfs -chmod -R o+rx /history;

    hdfs dfs -chmod -R a+rwx /history/mr-history/tmp;

    hdfs dfs -chown -R {{hdfs_user}}:{{hadoop_group}} /history;

    hdfs dfs -chown {{hdfs_user}}:{{hadoop_group}} /user;

    hdfs dfs -chown -R {{yarn_user}}:{{hadoop_group}} /history/app-logs /history/timeline-server;

    hdfs dfs -chown -R {{mapreduce_user}}:{{hadoop_group}}  /history/mr-history;

    hdfs dfs -chown -R {{spark_user}}:{{hadoop_group}}  /history/spark-history;

    hdfs dfs -chown -R abrsadm:abrsadm /user/abrsadm;
    kdestroy
  when: primary|bool
