# This file defines all the ports used by the system, for easier firewall config



# ZooKeeper
zookeeper_port: 2181
zookeeper_leader_election_port: 3888
zookeeper_follower_port: 2888


# HDFS
hdfs_namenode_rpc_port: 8020
hdfs_namenode_http_port: 9870
hdfs_namenode_https_port: 9871

hdfs_zkfc_port: 8019

hdfs_secondary_namenode_http_port: 9868
hdfs_secondary_namenode_https_port: 9869

hdfs_namenode_backup_rpc_port: 50100
hdfs_namenode_backup_http_port: 50105

hdfs_journalnode_http_port: 8480
hdfs_journalnode_https_port: 8481
hdfs_journalnode_rpc_port: 8485

hdfs_datanode_https_port: 9865
hdfs_datanode_rpc_port: 9866
hdfs_datanode_ipc_port: 9867
hdfs_datanode_http_port: 50475

hdfs_nfs_server_port: 2049
hdfs_nfs_mountd_port: 4242

hdfs_backupnode_service_port: 50100
hdfs_backupnode_http_port: 50105


yarn_timelineserver_http_port: 8188
yarn_timelineserver_https_port: 8190
yarn_timelineserver_port2: 10200

yarn_nodemanager_port: 45454

yarn_resourcemanager_rpc_port: 8050
yarn_resourcemanager_scheduler_port: 8030
yarn_resourcemanager_tracker_port: 8025
yarn_resourcemanager_admin_port: 8033
yarn_resourcemanager_http_port: 8088
yarn_resourcemanager_https_port: 8090

mapreduce_history_server_rpc_port: 10020
mapreduce_history_server_admin_port: 10033
mapreduce_history_server_http_port: 19888
mapreduce_history_server_https_port: 19890

mapreduce_shuffle_port: 13562

mapreduce_am_portrange: "50000-50200"

spark_history_server_https_port: 18480
spark_history_server_http_port: 18080

spark_portrange_width: 50

spark_ui_http_port: 4400
spark_ui_http_portrange: "{{spark_ui_http_port}}-{{spark_ui_http_port|int+spark_portrange_width|int}}"

spark_driver_http_port: 12000
spark_driver_http_portrange: "{{spark_driver_http_port}}-{{spark_driver_http_port|int+spark_portrange_width|int}}"

spark_blockmanager_http_port: 12500
spark_blockmanager_http_portrange: "{{spark_blockmanager_http_port}}-{{spark_blockmanager_http_port|int+spark_portrange_width|int}}"

rstudio_server_http_port: 8787

jupyterhub_port: 8000

zabbix_agent_listenport: "10050"

rsyslog_server_udp_port: 6514
rsyslog_server_tcp_port: 6514
syslog_forwarder_port: 10514

ports_per_role: # This dict maps roles names to ports

  #  HDFS
  hadoop_hdfs_namenode:
    - port: "{{hdfs_namenode_rpc_port}}"
    - port: "{{hdfs_namenode_http_port}}"
    - port: "{{hdfs_namenode_https_port}}"
    - port: "{{hdfs_zkfc_port}}"

  hadoop_hdfs_secondary_namenode:
    - port: "{{hdfs_secondary_namenode_http_port}}"
    - port: "{{hdfs_secondary_namenode_https_port}}"

  hadoop_hdfs_journalnode:
    - port: "{{hdfs_journalnode_rpc_port}}"
    - port: "{{hdfs_journalnode_https_port}}"
    - port: "{{hdfs_journalnode_https_port}}"

  hadoop_hdfs_datanode:
    - port: "{{hdfs_datanode_rpc_port}}"
    - port: "{{hdfs_datanode_ipc_port}}"
    - port: "{{hdfs_datanode_http_port}}"
    - port: "{{hdfs_datanode_https_port}}"

  hadoop_hdfs_backupnode:
  - port: "{{hdfs_backupnode_service_port}}"
  - port: "{{hdfs_backupnode_http_port}}"

  # YARN
  hadoop_yarn_timeline_server:
    - port: "{{yarn_timelineserver_http_port}}"
    - port: "{{yarn_timelineserver_https_port}}"
    - port: "{{yarn_timelineserver_port2}}"

  hadoop_yarn_node_manager:
    - port: "{{yarn_nodemanager_port}}"
    - port: "{{mapreduce_shuffle_port}}"
    - port: "{{mapreduce_am_portrange}}"
    - port: "{{spark_ui_http_portrange}}"
    - port: "{{spark_driver_http_portrange}}"
    - port: "{{spark_blockmanager_http_portrange}}"

  hadoop_yarn_resource_manager:
    - port: "{{yarn_resourcemanager_rpc_port}}"
    - port: "{{yarn_resourcemanager_scheduler_port}}"
    - port: "{{yarn_resourcemanager_tracker_port}}"
    - port: "{{yarn_resourcemanager_admin_port}}"
    - port: "{{yarn_resourcemanager_http_port}}"
    - port: "{{yarn_resourcemanager_https_port}}"

  # Mapreduce
  hadoop_mapreduce_history_server:
    - port: "{{mapreduce_history_server_rpc_port}}"
    - port: "{{mapreduce_history_server_admin_port}}"
    - port: "{{mapreduce_history_server_http_port}}"
    - port: "{{mapreduce_history_server_https_port}}"

  # Spark
  spark_history_server:
    - port: "{{spark_history_server_http_port}}"
    - port: "{{spark_history_server_https_port}}"

  # Zookeeper
  zookeeper_server:
    - port: "{{zookeeper_port}}"
    - port: "{{zookeeper_leader_election_port}}"
    - port: "{{zookeeper_follower_port}}"

  # Project nodes
  spark_client:
    - port: "{{spark_ui_http_portrange}}"
    - port: "{{spark_driver_http_portrange}}"
    - port: "{{spark_blockmanager_http_portrange}}"

  rstudio_server:
    - port: "{{rstudio_server_http_port}}"

  jupyterhub:
    - port: "{{jupyterhub_port}}"


  rsyslog_server:
    - port: "{{rsyslog_server_tcp_port}}"
      protocol: tcp

  rsyslog_client: []
#    - port: "{{syslog_forwarder_port}}" #TODO only open for localhost...
#      protocol: tcp
#      source: localhost

    # The Zabbix Agent module can do this itself, so do not duplicate it's work
    #  zabbix_agent:
    #     - port: "{{zabbix_agent_listenport}}"

  hadoop: [] # This ensures that the firewall is started for all hadoop nodes

