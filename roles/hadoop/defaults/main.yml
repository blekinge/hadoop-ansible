---
#Flag if you just need to depend on this role to get variables
install_hadoop: true

wipe_hdfs: false

# hadoop basic vars
# Set a local file here, if you do not want to download it dynamicallyl
hadoop_version: "3.3.0"
hadoop_download: http://ftp.download-by.net/apache/hadoop/common/hadoop-{{hadoop_version}}/hadoop-{{hadoop_version}}.tar.gz
hadoop_path: "/usr/local/hadoop"
hadoop_home: "{{ hadoop_path }}/hadoop-{{ hadoop_version }}"

current_hadoop_home: "{{ hadoop_path }}/current"

hadoop_config_path: "/etc/hadoop/conf"
hadoop_tmp: "/tmp/hadoop"
hadoop_log_dir: "/var/log/hadoop"
hadoop_pid_dir: "/var/run/hadoop"

#Loggers
hadoop_daemon_logger: "INFO,DRFA,SYSLOG"
hdfs_daemon_logger: "{{hadoop_daemon_logger}}"
yarn_daemon_logger: "{{hadoop_daemon_logger}},EWMA"
mapreduce_daemon_logger: "{{hadoop_daemon_logger}}"

mapreduce_jobsummary_logger: "INFO,JSA"
yarn_resourcemanager_appsummary_logger: "INFO,RMSUMMARY"

hadoop_security_logger: "INFO,DRFAS,SYSLOG_SECURITY"
hdfs_security_logger: "{{hadoop_security_logger}}"
mapreduce_security_logger: "{{hadoop_security_logger}}"

hadoop_audit_logger: "INFO,SYSLOG_AUDIT"
hdfs_audit_logger: "{{hadoop_audit_logger}},DRFAAUDIT"
yarn_nodemanager_audit_logger: "{{hadoop_audit_logger}},NMAUDIT"
yarn_resourcemanager_audit_logger: "{{hadoop_audit_logger}},RMAUDIT"


hdfs_namenode_memory: "4096m"
hdfs_datanode_memory: "2048m"

mapreduce_map_java_memory: "1536m"
mapreduce_map_yarn_memory: 2048
mapreduce_reduce_java_memory: "1536m"
mapreduce_reduce_yarn_memory: 2048
mapreduce_am_java_memory: "1536m"
mapreduce_am_yarn_memory: 2048
mapreduce_task_sort_memory: 1024

yarn_nodemanager_available_cpu_cores: 1
yarn_nodemanager_available_memory: 1024

yarn_scheduler_min_cpu_cores: 1
yarn_scheduler_max_cpu_cores: 2
yarn_scheduler_min_memory: 1024
yarn_scheduler_max_memory: 3072

#HDFS
hadoop_dfs_name: "/hdfs/dfs/name"
hadoop_dfs_journal: "/hdfs/dfs/journal"


hdfs_name: "KAC"

hdfs_data_dirs: []

hdfs_data_dirs_joined:  "{{ hdfs_data_dirs | join(',') }}"


#YARN

yarn_timeline_store: "/hadoop/yarn/timeline"


yarn_timelineserver: "{{ groups['hostgroup_yarn_timeline_servers'] | map('extract',hostvars, 'ansible_fqdn') | first }}"


yarn_data_dirs: []
#  - /data/sdb1/yarn
#  - /data/sdc1/hdfs
#  - /data/sdd1/hdfs
#  - /data/sde1/hdfs
#  - /data/sdf1/hdfs
#  - /data/sdg1/hdfs

yarn_data_dirs_joined:  "{{ yarn_data_dirs | join(',') }}"

yarn_application_logs_dir: "{{ hadoop_log_dir }}/{{ yarn_user.name }}/application-logs/"
#yarn_user.user_logs: "/hadoop/yarn/

yarn_timeline_server_dir: '/history/timeline-server'

yarn_nodemanager_remote_app_log_dir: "/history/app-logs"

#TODO more than one?
mapreduce_history_server_host: "{{ groups['hostgroup_mapreduce_history_servers'] | map('extract',hostvars, 'ansible_fqdn') | first }}"

mapreduce_create_path:
  - "/hadoop/mapreduce"

mapreduce_jobhistory_recovery_store_leveldb_path: /hadoop/mapreduce/jhs

mapreduce_jobhistory_dir: '/history/mr-history'


zookeeper_quorum: "{{ groups['hostgroup_zookeeper_servers'] | map('extract',hostvars, 'ansible_fqdn') | zip_longest([], fillvalue=zookeeper_port) | map('join', ':') | join(',') }}"

